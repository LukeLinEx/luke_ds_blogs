{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "You must have heard about maximal likelihood estimate if you have ever studied machine learning. Many found this one of the abstract concepts to understand. Most likely, this is because we usually deal only with determined events in our everyday lives and rarely think about likelihood.\n",
    "\n",
    "So let's think a little bit about likelihood. You might find this too abstract a concept but it's nothing more than a refinement of everyday thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Variable, Distribution and Likelihood\n",
    "\n",
    "To talk about likelihood, we need to start with some scary terms: random variable and distribution.\n",
    "\n",
    "#### Random Variable\n",
    "We know that a variable represents a value. For example, `x=1` means we have a variable `x` which represents the value `1`.\n",
    "<br><br>\n",
    "Great! But what is a random variable?\n",
    "<br><br>\n",
    "Similar to a variable, a random variable also represents value. The difference is that we don't know for sure what the value a random variable represents. For example, the `outcome` of flipping a coin can be a variable after we actually flip a coin. It's either `head` or `tail`. But before we flip the coin, the `outcome` can be treated as a random variable - a value that we don't know for sure.\n",
    "\n",
    "Even we don't know the value of a random variable, we need to get to know something about it. Otherwise there is no study can be done whatsoever! Usually for a random variable we need to know at least the possible values (head or tail in the coin flipping example). We would also like to know how likely we end up with each possible value. And that's what a distribution tells us.\n",
    "\n",
    "#### Distribution\n",
    "Very often people state not only \"flip a coin\", but \"flip a **fair** coin\". What does the word \"fair\" tell us? It tells us that there is 50% chance for head, and 50% for tail.\n",
    "\n",
    "It tells us how likely we end up with each possible value! It's a **distribution**!\n",
    "\n",
    "For people who found the word \"distribution\" too intimidating, it's nothing but a table in this example.\n",
    "\n",
    "|Event|Probability|\n",
    "|-----|-----------|\n",
    "|head | 0.5   |\n",
    "|tail | 0.5   |\n",
    "\n",
    "This distribution is called the Bernoulli distribution with 50% probability of success. Bernoulli distribution is for binary outcomes, and one can define either to be a success. The outcome of flipping a fair coin can be rephrased as **a random variable that has the Bernoulli distribution with 50% probability of success**.\n",
    "\n",
    "That \"50% probability of success\" is a parameter of the Bernoulli distribution. If a coin is not fair, for example the probability for head is 60%, then we can \"model\" the scenario with the Bernoulli distribution with 60% probability of success, or equivalently the table below:\n",
    "\n",
    "|Event|Probability|\n",
    "|-----|-----------|\n",
    "|head | 0.6   |\n",
    "|tail | 0.4   |\n",
    "\n",
    "For this Bernoulli distribution, the parameter \"probability of success is 60%\". The Bernoulli distribution might refer to a family of distirbution parametrized by its probability of success.\n",
    "\n",
    "#### Likelihood\n",
    "Once the distribution gives us the likelihood of a single event, we can actually achieve more. For example, if we flip a fair coin three times, how likely do we end up with the result: `head`, `head`, `tail`?\n",
    "\n",
    "Assuming that the result of each flipping is independent, then our \"fair coin\" distribution would predict the likelihood of the collective result to be the product of the probability of the single events, namely, 0.5 x 0.5 x 0.5 = 0.125:\n",
    "\n",
    "|head |head |tail |    |\n",
    "|----|----|----|----|----|-------|\n",
    "| 0.5| 0.5| 0.5|0.125|\n",
    "\n",
    "What about the Bernoulli distribution with 60% probability of success? What would it say about this `head`, `head`, `tail` result? Again, the product of the probabilities would be 0.6 x 0.6 x 0.4 = 0.144:\n",
    "\n",
    "|head |head |tail |    |\n",
    "|----|----|----|----|----|-------|\n",
    "| 0.6| 0.6| 0.4|0.144|\n",
    "\n",
    "Comparing the two distributions, we found that the latter predicting higher likelihood to the data: `head`, `head`, `tail`. In this case, we say that the Bernoulli distribution with 60% probability of success **fits** this data better.  A reasonable questions following would be: are there other parameter that fits even better? The so called **maximum likelihood estimate** is a process to find the parameter of which the distribution predicts the highest likelihood for the data.\n",
    "\n",
    "Before we get to the maximum likelihood estimate, let's take a look at another very important distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Distribution\n",
    "\n",
    "The outcome of the Bernoulli distribution is discrete and finite. This can't be used to model a random variable with numerical outcome.\n",
    "\n",
    "For example, we might want to model the return of an investment. This is a numerial outcome, which is different from discrete outcome in the following ways:\n",
    "- There are infinite possible values. The return can be 0, 0.1, -0.1, 0.2, -0.2, or any real number. Indeed, even extremely unlikely, it can be a huge positive or negative number.\n",
    "- The possible values are continuous. The return can be 0.1, 0.01, 0.001, 0.0001, ..., etc. It can be arbitrarily close to 0 wihtout touching 0. \n",
    "\n",
    "Therefore we can no longer summarise the likelihood of all the possible events in a table. The famous **bell curve** comes in handy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Density Function\n",
    "\n",
    "The bell curve is actually the graph of the **probability density function**, which characterized a Gaussian distribution. Indeed, to specify a Guassian distribution, one needs to specify the probability it predicts for each possible value. For example, suppose we have a random variable has the **standard normal distribution** (defined later), whose probability density curve is as below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://18.224.55.217:5050/likelihood\" width=600 height=500></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"http://18.224.55.217:5050/likelihood\" width=600 height=500></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then all the possible values are listed along the x axis. And the height of the curve represents the likelihood that the x occurs. This allow us to look up the probability for any possible x. If you just submit the x value in the app above, it will return the likelihood of the x. Some of the likelihood are listed below:\n",
    "\n",
    "|Value|Probability Density|\n",
    "|-----|-----------|\n",
    "|-1.18 | 0.199  |\n",
    "|-1 | 0.242  |\n",
    "|0| 0.399   |\n",
    "|1 | 0.242   |\n",
    "|1.18 | 0.199   |\n",
    "\n",
    "Note that the probability density is used here instead of the probability. The probability density is not probability but it does represents likelihood. That being said, numbers around `0` are twice more likely to occur than numbers around `1.181`, because the probability density of `x=0` is about twice of the probability density of `x=1.181`. The reason why the probability density is used here instead of probability is not in the scope of this blog but it's not difficult to find literature about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters of Gaussian Distributions\n",
    "\n",
    "Different Gaussian distributions have different probability density functions. Just like the Bernoulli distributions are parametrized by the probability of success, the Gaussian distributions also have some parameters: mean and variance. The standard Gaussian distribution is actually the Gaussian distribution with $\\mu=0$ and $\\sigma^2=1$.\n",
    "\n",
    "The formula of the probability density function of an Gaussian distribution is\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4abaca87a10ecfa77b5a205056523706fe6c9c3f\">\n",
    "\n",
    "In the formula $\\mu$ represents the mean and $\\sigma^2$ stands for variance. Note that in the right hand side the $\\mu, \\sigma^2$ and $x$, are unknown and the rest are constants. So if the mean and the variance are provided, we can use the formula to compute the probability density for each $x$. In the app above, we actually visualized the normal distribution with $\\mu=0$ and $\\sigma^2=1$. A normal distribution with different parameters will result in different predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Distribution of Different Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://18.224.55.217:5050/likelihood_different_mu\" width=600 height=500></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"http://18.224.55.217:5050/likelihood_different_mu\" width=600 height=500></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, \n",
    "- the blue curve is the probability density function of the Gaussian with $\\mu=0$ and $\\sigma^2=1$. \n",
    "- the green curve is the probability density function of the Gaussian with $\\mu=1$ and $\\sigma^2=1$. \n",
    "\n",
    "They are different in their means. We can see that the different means result in different center of the two curves. Try different x and see how the two distribution are different in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Distribution of Different Variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://18.224.55.217:5050/likelihood_different_var\" width=600 height=500></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"http://18.224.55.217:5050/likelihood_different_var\" width=600 height=500></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, \n",
    "- the blue curve is the probability density function of the Gaussian with $\\mu=0$ and $\\sigma^2=1$. \n",
    "- the green curve is the probability density function of the Gaussian with $\\mu=0$ and $\\sigma^2=3$. \n",
    "\n",
    "They are different in their variance. We can see that the greater variance result in wider bell curve. Try different x and see how the two distribution are different in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood\n",
    "\n",
    "Now we know how the probability density function of a Gaussian distribution gives us the likelihood of a single event. How do we find the likelihood of some collective events?\n",
    "\n",
    "For example, if we record the return of our investiment and end up with percentage 1, 3 and -1.5.  How likely would our standard Gaussian distribution predict that these occur? \n",
    "\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/lukepublicbucket/zero_one.png\">\n",
    "\n",
    "Again we will assume independence on the individual return (this might not be realistic but makes the problem simple enough to proceed), the likelihood for the collective outcome is just the product: \n",
    "```\n",
    "0.13 x 0.242 x 0.004 = 0.00012584\n",
    "```\n",
    "\n",
    "The Gaussian distribution with $\\mu=1$ and $\\sigma^2=1$ will predict different likelihood:\n",
    "\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/lukepublicbucket/one_one.png\">\n",
    "```\n",
    "0.018 x 0.399 x 0.054 = 0.000387828\n",
    "```\n",
    "\n",
    "The Gaussian distribution with $\\mu=0$ and $sigma^2=3$ will predict:\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/lukepublicbucket/zero_three.png\">\n",
    "```\n",
    "0.158 x 0.195 x 0.051 = 0.00157131\n",
    "```\n",
    "\n",
    "Therefore, if we collect the return and end up with our 1, 3 and -1.5, and would like to select a Gaussian distribution that model the data best, we will go with the third one. It predict the highest likelihood for the collective values to happen, so it fits the data best among the three Guassian distribution. Obviously we have more than these three Gaussian distribution. To find the best one among the all, we need to apply the **maximum likelihood estimate**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
